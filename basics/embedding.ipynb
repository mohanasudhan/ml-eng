{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Embedding?\n",
    "\n",
    "Embedding converts categories into continuous vectors\n",
    "\n",
    "Embedding, mainly used in deep learning, converts categorical data into dense vectors of continuous numbers. These vectors capture semantic relationships between categories and reduce dimensionality efficiently. Pre-trained embeddings like Word2Vec, GloVe, and FastText are available for tasks like natural language processing (NLP) and recommendation systems. Trainable embeddings are learned during model training for specific tasks.\n",
    "\n",
    "Advantages of embeddings include their compactness and ability to capture semantic relationships, improving model performance. However, embeddings are computationally expensive and less interpretable compared to encodings.\n",
    "\n",
    "The choice between encoding and embedding depends on the dataset size, number of categories, and specific problem requirements. One-hot encoding is suitable for small datasets with few categories, while embeddings are preferred for large datasets, especially in NLP tasks and recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Obtaining dependency information for gensim from https://files.pythonhosted.org/packages/63/46/5feab9c524a380bfa9f9f1c0d065743280dca30b216ab4c7a231f22dbed7/gensim-4.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading gensim-4.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/mohanasudhangandhi/.pyenv/versions/venv-3.11/lib/python3.11/site-packages (from gensim) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/mohanasudhangandhi/.pyenv/versions/venv-3.11/lib/python3.11/site-packages (from gensim) (1.12.0)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Obtaining dependency information for smart-open>=1.8.1 from https://files.pythonhosted.org/packages/ad/08/dcd19850b79f72e3717c98b2088f8a24b549b29ce66849cd6b7f44679683/smart_open-7.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smart_open-7.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Obtaining dependency information for wrapt from https://files.pythonhosted.org/packages/0f/16/ea627d7817394db04518f62934a5de59874b587b792300991b3c347ff5e0/wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Downloading gensim-4.3.2-cp311-cp311-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.0.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Installing collected packages: wrapt, smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-7.0.1 wrapt-1.16.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# The Gensim library provides tools and algorithms for topic modeling, \n",
    "# document similarity analysis, and other natural language processing (NLP) tasks.\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'machine': [ 0.1476101  -0.03066943 -0.09073226  0.13108103 -0.09720321]\n",
      "Embedding for sentence 'I love machine learning': [-0.01302523  0.02925177  0.0208698   0.0414466  -0.10625307]\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Sample data\n",
    "sentences = [['I', 'love', 'machine', 'learning'],\n",
    "             ['machine', 'learning', 'is', 'awesome'],\n",
    "             ['deep', 'learning', 'is', 'interesting']]\n",
    "\n",
    "# Training Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=5, window=3, min_count=1, sg=1)\n",
    "\n",
    "# Getting embedding for a word\n",
    "word_embedding = model.wv['machine']\n",
    "print(\"Embedding for 'machine':\", word_embedding)\n",
    "\n",
    "# Getting embedding for a sentence\n",
    "sentence_embedding = np.mean([model.wv[word] for word in sentences[0]], axis=0)\n",
    "print(\"Embedding for sentence 'I love machine learning':\", sentence_embedding)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
