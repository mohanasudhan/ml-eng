{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/mohanasudhangandhi/.pyenv/versions/venv-3.11/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in /Users/mohanasudhangandhi/.pyenv/versions/venv-3.11/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mohanasudhangandhi/.pyenv/versions/venv-3.11/lib/python3.11/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/mohanasudhangandhi/.pyenv/versions/venv-3.11/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/mohanasudhangandhi/.pyenv/versions/venv-3.11/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/mohanasudhangandhi/.pyenv/versions/venv-3.11/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/mohanasudhangandhi/.pyenv/versions/venv-3.11/lib/python3.11/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mohanasudhangandhi/.pyenv/versions/venv-3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mohanasudhangandhi/.pyenv/versions/venv-3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a transformer?\n",
    "The Transformer model acts like a sophisticated tool that helps you understand and summarize conversations more effectively. It processes input sequences through various layers to extract important information and provide a concise summary of the conversation's key points.\n",
    "\n",
    "Imagine you're in a bustling classroom where students are engaged in conversations. Your task is to understand these conversations and provide a summary of what's being discussed.\n",
    "\n",
    "1. **Positional Encoding**:\n",
    "   - You have a special notebook to write down what each student says. However, you also need to remember who said what and in what order. So, you assign a unique code to each student's message and note down their position in the conversation. This way, you can keep track of the conversation's flow and structure.\n",
    "\n",
    "2. **Transformer Model**:\n",
    "   - Now, you start processing the conversation using a special device called a \"Transformer\". This device helps you understand and summarize the conversation more effectively.\n",
    "   - **Embedding Layer**: You first listen to each student's message and translate it into a language that the Transformer understands. It's like translating each student's words into a common language that you and the Transformer can both understand.\n",
    "   - **Positional Encoding**: Next, you add additional information to your notes to indicate the order in which each student spoke. This helps the Transformer understand the flow of the conversation and who said what.\n",
    "   - **Transformer Encoder Layers**: You then process your notes through a series of special layers within the Transformer device. Each layer helps you focus on different aspects of the conversation, such as understanding the relationships between different students' messages and identifying important points.\n",
    "   - **Linear Output Layer**: Finally, after processing the conversation through all the layers of the Transformer, you summarize the main points and provide a clear summary of what was discussed. This summary is like the final output of the Transformer, which captures the key information from the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, d_model, nhead, num_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model, nhead), num_layers)\n",
    "        self.fc = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src)\n",
    "        src = self.positional_encoding(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.fc(output)\n",
    "        return F.log_softmax(output, dim=-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
